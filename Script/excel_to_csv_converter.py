#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Excel to CSV ë³€í™˜ê¸°
c:\K04_cashflow_1\Ledgersì˜ ëª¨ë“  Excel íŒŒì¼ì„ CSVë¡œ ë³€í™˜

ì‘ì„±ì¼: 2025-08-22
ëª©ì : ì›ì¥ ë°ì´í„° ì²˜ë¦¬ ì†ë„ í–¥ìƒ ë° ë²”ìš©ì„± í™•ë³´
"""

import os
import pandas as pd
from pathlib import Path
from datetime import datetime
import logging

# UTF-8 ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('./log/csv_conversion.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class ExcelToCSVConverter:
    """Excel íŒŒì¼ì„ CSVë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, source_dir="C:\\K04_cashflow_1\\Ledgers", 
                 target_dir="C:\\K04_cashflow_1\\CSV_Data"):
        self.source_dir = Path(source_dir)
        self.target_dir = Path(target_dir)
        self.conversion_stats = {
            'total_files': 0,
            'converted_files': 0,
            'total_sheets': 0,
            'converted_sheets': 0,
            'failed_conversions': [],
            'start_time': datetime.now()
        }
        
        # CSV ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.target_dir.mkdir(exist_ok=True)
        
        logging.info(f"[CSVë³€í™˜ê¸°ì´ˆê¸°í™”] [ì›ë³¸ë””ë ‰í† ë¦¬_{self.source_dir}] [ì¶œë ¥ë””ë ‰í† ë¦¬_{self.target_dir}]")
    
    def convert_all_excel_files(self):
        """Ledgers í´ë”ì˜ ëª¨ë“  Excel íŒŒì¼ì„ CSVë¡œ ë³€í™˜"""
        excel_files = list(self.source_dir.glob("*.xlsx"))
        self.conversion_stats['total_files'] = len(excel_files)
        
        logging.info(f"[ë³€í™˜ì‹œì‘] [íŒŒì¼ìˆ˜_{len(excel_files)}ê°œ]")
        
        for excel_file in excel_files:
            if not excel_file.name.startswith('~$'):  # ì„ì‹œ íŒŒì¼ ì œì™¸
                try:
                    self._convert_single_file(excel_file)
                    self.conversion_stats['converted_files'] += 1
                except Exception as e:
                    error_info = f"{excel_file.name}: {str(e)}"
                    self.conversion_stats['failed_conversions'].append(error_info)
                    logging.error(f"[íŒŒì¼ë³€í™˜ì‹¤íŒ¨] [íŒŒì¼_{excel_file.name}] [ì˜¤ë¥˜_{str(e)}]")
        
        self._generate_conversion_report()
    
    def _convert_single_file(self, excel_file):
        """ë‹¨ì¼ Excel íŒŒì¼ ë³€í™˜"""
        logging.info(f"[íŒŒì¼ë³€í™˜ì‹œì‘] [íŒŒì¼_{excel_file.name}]")
        
        # ì—°ë„ë³„ í´ë” ìƒì„±
        year = self._extract_year_from_filename(excel_file.name)
        year_dir = self.target_dir / f"{year}ë…„"
        year_dir.mkdir(exist_ok=True)
        
        # Excel íŒŒì¼ ì½ê¸° (ëª¨ë“  ì‹œíŠ¸)
        excel_data = pd.read_excel(excel_file, sheet_name=None, engine='openpyxl')
        
        converted_sheets = 0
        for sheet_name, df in excel_data.items():
            try:
                # CSV íŒŒì¼ëª… ìƒì„±
                safe_sheet_name = self._sanitize_filename(sheet_name)
                csv_filename = f"{safe_sheet_name}.csv"
                csv_path = year_dir / csv_filename
                
                # ë°ì´í„° ì „ì²˜ë¦¬
                processed_df = self._preprocess_sheet_data(df, sheet_name)
                
                # CSVë¡œ ì €ì¥ (UTF-8 ì¸ì½”ë”©)
                processed_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
                
                converted_sheets += 1
                self.conversion_stats['converted_sheets'] += 1
                
                logging.info(f"[ì‹œíŠ¸ë³€í™˜ì™„ë£Œ] [ì‹œíŠ¸_{sheet_name}] [í–‰ìˆ˜_{len(processed_df)}] [íŒŒì¼_{csv_filename}]")
                
            except Exception as e:
                logging.error(f"[ì‹œíŠ¸ë³€í™˜ì‹¤íŒ¨] [ì‹œíŠ¸_{sheet_name}] [ì˜¤ë¥˜_{str(e)}]")
        
        logging.info(f"[íŒŒì¼ë³€í™˜ì™„ë£Œ] [íŒŒì¼_{excel_file.name}] [ë³€í™˜ì‹œíŠ¸ìˆ˜_{converted_sheets}ê°œ]")
        self.conversion_stats['total_sheets'] += len(excel_data)
    
    def _extract_year_from_filename(self, filename):
        """íŒŒì¼ëª…ì—ì„œ ì—°ë„ ì¶”ì¶œ"""
        if "2022" in filename:
            return "2022"
        elif "2023" in filename:
            return "2023"
        elif "2024" in filename:
            return "2024"
        elif "2025" in filename:
            return "2025"
        else:
            return "ê¸°íƒ€"
    
    def _sanitize_filename(self, sheet_name):
        """ì‹œíŠ¸ëª…ì„ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ ì •ë¦¬"""
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ëŒ€ì²´
        safe_name = sheet_name.replace('/', '_').replace('\\', '_').replace(':', '_')
        safe_name = safe_name.replace('*', '_').replace('?', '_').replace('"', '_')
        safe_name = safe_name.replace('<', '_').replace('>', '_').replace('|', '_')
        
        # ê´„í˜¸ëŠ” ìœ ì§€ (ê³„ì •ì½”ë“œ êµ¬ë¶„ìš©)
        return safe_name
    
    def _preprocess_sheet_data(self, df, sheet_name):
        """ì‹œíŠ¸ ë°ì´í„° ì „ì²˜ë¦¬"""
        # 1. ì»¬ëŸ¼ëª… í‘œì¤€í™”
        if len(df.columns) >= 7:
            df.columns = ['ë‚ ì§œ', 'ì ìš”', 'ì½”ë“œ', 'ê±°ë˜ì²˜', 'ì°¨ë³€', 'ëŒ€ë³€', 'ì”ì•¡'] + list(df.columns[7:])
        
        # 2. í—¤ë” í–‰ ì œê±° (ì‹¤ì œ ë°ì´í„°ë§Œ ìœ ì§€)
        # "ë‚ ì§œ" í—¤ë”ê°€ ìˆëŠ” í–‰ ì´í›„ë¶€í„° ë°ì´í„° ì‹œì‘
        data_start_row = 0
        for idx, row in df.iterrows():
            if pd.notna(row.iloc[0]) and str(row.iloc[0]).strip() == 'ë‚ ì§œ':
                data_start_row = idx + 1
                break
        
        if data_start_row > 0:
            df = df.iloc[data_start_row:].copy()
        
        # 3. ë¹ˆ í–‰ ì œê±°
        df = df.dropna(how='all')
        
        # 4. ê³„ì • ì •ë³´ ë©”íƒ€ë°ì´í„° ì¶”ê°€
        account_code = self._extract_account_code(sheet_name)
        df.insert(0, 'ê³„ì •ì½”ë“œ', account_code)
        
        # 5. ë°ì´í„° íƒ€ì… ì •ë¦¬
        numeric_columns = ['ì°¨ë³€', 'ëŒ€ë³€', 'ì”ì•¡']
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        
        # 6. ë‚ ì§œ í˜•ì‹ ì •ë¦¬
        if 'ë‚ ì§œ' in df.columns:
            df['ë‚ ì§œ'] = df['ë‚ ì§œ'].astype(str).str.replace('0', '', regex=False)
        
        return df
    
    def _extract_account_code(self, sheet_name):
        """ì‹œíŠ¸ëª…ì—ì„œ ê³„ì •ì½”ë“œ ì¶”ì¶œ"""
        import re
        # "ìˆ«ì_ì´ë¦„(ê³„ì •ì½”ë“œ)" íŒ¨í„´ì—ì„œ ê³„ì •ì½”ë“œ ì¶”ì¶œ
        match = re.search(r'\((\d+)\)', sheet_name)
        if match:
            return match.group(1)
        
        # íŒ¨í„´ì´ ì—†ìœ¼ë©´ ì‹œíŠ¸ëª… ì•ì˜ ìˆ«ì ì‚¬ìš©
        if '_' in sheet_name:
            parts = sheet_name.split('_')
            if len(parts) > 1 and parts[1].replace('(', '').replace(')', '').isdigit():
                return parts[1].replace('(', '').replace(')', '')[:5]
        
        return "UNKNOWN"
    
    def convert_specific_file(self, filename):
        """íŠ¹ì • íŒŒì¼ë§Œ ë³€í™˜"""
        excel_file = self.source_dir / filename
        if excel_file.exists():
            self._convert_single_file(excel_file)
            logging.info(f"[ê°œë³„íŒŒì¼ë³€í™˜ì™„ë£Œ] [íŒŒì¼_{filename}]")
        else:
            logging.error(f"[íŒŒì¼ì—†ìŒ] [íŒŒì¼_{filename}]")
    
    def create_consolidated_csv(self):
        """ëª¨ë“  CSV íŒŒì¼ì„ í†µí•©í•œ ë§ˆìŠ¤í„° CSV ìƒì„±"""
        all_data = []
        
        for year_dir in self.target_dir.iterdir():
            if year_dir.is_dir():
                for csv_file in year_dir.glob("*.csv"):
                    try:
                        df = pd.read_csv(csv_file, encoding='utf-8-sig')
                        df['ì—°ë„'] = year_dir.name.replace('ë…„', '')
                        df['ì›ë³¸íŒŒì¼'] = csv_file.name
                        all_data.append(df)
                    except Exception as e:
                        logging.error(f"[í†µí•©CSVìƒì„±ì‹¤íŒ¨] [íŒŒì¼_{csv_file}] [ì˜¤ë¥˜_{str(e)}]")
        
        if all_data:
            consolidated_df = pd.concat(all_data, ignore_index=True)
            consolidated_path = self.target_dir / "ì „ì²´_ì›ì¥ë°ì´í„°_í†µí•©.csv"
            consolidated_df.to_csv(consolidated_path, index=False, encoding='utf-8-sig')
            
            logging.info(f"[í†µí•©CSVìƒì„±ì™„ë£Œ] [ê²½ë¡œ_{consolidated_path}] [ì´í–‰ìˆ˜_{len(consolidated_df)}]")
            return consolidated_path
        
        return None
    
    def _generate_conversion_report(self):
        """ë³€í™˜ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
        end_time = datetime.now()
        duration = end_time - self.conversion_stats['start_time']
        
        report = {
            "ë³€í™˜ì™„ë£Œì‹œê°„": end_time.strftime('%Y-%m-%d %H:%M:%S'),
            "ì´ì²˜ë¦¬ì‹œê°„": str(duration),
            "ì²˜ë¦¬í†µê³„": {
                "ì´íŒŒì¼ìˆ˜": self.conversion_stats['total_files'],
                "ë³€í™˜ì„±ê³µíŒŒì¼": self.conversion_stats['converted_files'],
                "ì´ì‹œíŠ¸ìˆ˜": self.conversion_stats['total_sheets'],
                "ë³€í™˜ì„±ê³µì‹œíŠ¸": self.conversion_stats['converted_sheets']
            },
            "ì„±ê³µë¥ ": {
                "íŒŒì¼ì„±ê³µë¥ ": f"{(self.conversion_stats['converted_files'] / max(1, self.conversion_stats['total_files']) * 100):.1f}%",
                "ì‹œíŠ¸ì„±ê³µë¥ ": f"{(self.conversion_stats['converted_sheets'] / max(1, self.conversion_stats['total_sheets']) * 100):.1f}%"
            },
            "ì‹¤íŒ¨ëª©ë¡": self.conversion_stats['failed_conversions']
        }
        
        # JSON ë³´ê³ ì„œ ì €ì¥
        report_path = self.target_dir / f"conversion_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        import json
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # ì½˜ì†” ì¶œë ¥
        print(f"\nğŸ“Š CSV ë³€í™˜ ì™„ë£Œ ë³´ê³ ì„œ")
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.target_dir}")
        print(f"ğŸ“ˆ íŒŒì¼ ì„±ê³µë¥ : {report['ì„±ê³µë¥ ']['íŒŒì¼ì„±ê³µë¥ ']}")
        print(f"ğŸ“‹ ì‹œíŠ¸ ì„±ê³µë¥ : {report['ì„±ê³µë¥ ']['ì‹œíŠ¸ì„±ê³µë¥ ']}")
        print(f"â±ï¸  ì´ ì²˜ë¦¬ì‹œê°„: {report['ì´ì²˜ë¦¬ì‹œê°„']}")
        
        if report['ì‹¤íŒ¨ëª©ë¡']:
            print(f"âš ï¸  ì‹¤íŒ¨ í•­ëª©: {len(report['ì‹¤íŒ¨ëª©ë¡'])}ê°œ")
            for failure in report['ì‹¤íŒ¨ëª©ë¡']:
                print(f"   - {failure}")
        
        logging.info(f"[ë³€í™˜ë³´ê³ ì„œìƒì„±] [ê²½ë¡œ_{report_path}]")
        return report_path


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”„ Excel to CSV ë³€í™˜ ì‹œì‘...")
    
    converter = ExcelToCSVConverter()
    
    # ëª¨ë“  Excel íŒŒì¼ ë³€í™˜
    converter.convert_all_excel_files()
    
    # í†µí•© CSV ìƒì„±
    print("\nğŸ”— í†µí•© CSV íŒŒì¼ ìƒì„± ì¤‘...")
    consolidated_path = converter.create_consolidated_csv()
    
    if consolidated_path:
        print(f"âœ… í†µí•© CSV ìƒì„± ì™„ë£Œ: {consolidated_path}")
    
    print("\nğŸ¯ CSV ë³€í™˜ ì‘ì—… ì™„ë£Œ!")


if __name__ == "__main__":
    main()